<!doctype html><html lang=zh-CN data-theme=dark><head><meta charset=UTF-8><meta name=viewport content="width=device-width"><meta name=theme-color content="#222" media="(prefers-color-scheme: dark)"><meta name=generator content="Hugo 0.121.1"><link rel="shortcut icon" type=image/x-icon href=/imgs/icons/favicon.ico><link rel=icon type=image/x-icon href=/imgs/icons/favicon.ico><link rel=icon type=image/png sizes=16x16 href=/imgs/icons/favicon_16x16_next.png><link rel=icon type=image/png sizes=32x32 href=/imgs/icons/favicon_32_32_next.png><link rel=apple-touch-icon sizes=180x180 href=/imgs/icons/apple_touch_icon_next.png><meta itemprop=name content="机器学习中的特征工程"><meta itemprop=description content="featureenginering-of-machinelearning"><meta itemprop=datePublished zgotmplz><meta itemprop=dateModified zgotmplz><meta itemprop=image content="/img/avatar.jpg"><meta itemprop=keywords content="机器学习"><meta property="og:type" content="article"><meta property="og:title" content="机器学习中的特征工程"><meta property="og:description" content="featureenginering-of-machinelearning"><meta property="og:image" content="/img/avatar.jpg"><meta property="og:image:width" content="312"><meta property="og:image:height" content="312"><meta property="og:image:type" content="image/jpeg/png/svg/jpg"><meta property="og:url" content="/post/featureenginering-of-machinelearning/"><meta property="og:site_name" content="Patrick's Blog"><meta property="og:locale" content="zh-CN"><meta property="article:author" content="Patrick"><meta property="article:published_time" content="2020-02-03 15:42:32 +0800 CST"><meta property="article:modified_time" content="2024-04-04 11:37:12 +0800 CST"><link type=text/css rel=stylesheet href=https://cdn.staticfile.org/font-awesome/6.1.2/css/all.min.css><link type=text/css rel=stylesheet href=https://cdn.staticfile.org/animate.css/3.1.1/animate.min.css><link type=text/css rel=stylesheet href=https://cdn.staticfile.org/viewerjs/1.11.0/viewer.min.css><link rel=stylesheet href=/css/main.min.a987c3fbca3727259a25c99140afed885cbffe7b77dba717d89bbe0780afcd01.css><style type=text/css>.post-footer,.flinks-list-footer hr:after{content:"~ 我可是有底线的哟 ~"}</style><script type=text/javascript>(function(){localDB={set:function(e,t,n){if(n===0)return;const s=new Date,o=n*864e5,i={value:t,expiry:s.getTime()+o};localStorage.setItem(e,JSON.stringify(i))},get:function(e){const t=localStorage.getItem(e);if(!t)return void 0;const n=JSON.parse(t),s=new Date;return s.getTime()>n.expiry?(localStorage.removeItem(e),void 0):n.value}},theme={active:function(){const e=localDB.get("theme");if(e==null)return;theme.toggle(e),window.matchMedia("(prefers-color-scheme: dark)").addListener(function(e){theme.toggle(e.matches?"dark":"light")})},toggle:function(e){document.documentElement.setAttribute("data-theme",e),localDB.set("theme",e,2);const t=document.querySelector("iframe.giscus-frame");if(t){const n={setConfig:{theme:e}};t.contentWindow.postMessage({giscus:n},"https://giscus.app")}}},theme.active()})(window)</script><script class=next-config data-name=page type=application/json>{"comments":false,"isHome":false,"isPage":true,"math":{"css":{"file":"dist/katex.min.css","name":"katex","version":"0.16.0"},"js":[{"file":"dist/katex.min.js","name":"katex","version":"0.16.0"},{"alias_name":"katex","file":"dist/contrib/auto-render.min.js","name":"auto-render","version":"0.16.0"}],"render":"katex"},"path":"featureenginering-of-machinelearning","permalink":"/post/featureenginering-of-machinelearning/","title":"机器学习中的特征工程","waline":{"js":[{"alias":"waline","alias_name":"@waline/client","file":"dist/pageview.js","name":"pageview","version":"2.13.0"},{"alias":"waline","alias_name":"@waline/client","file":"dist/comment.js","name":"comment","version":"2.13.0"}]}}</script><script type=text/javascript>document.addEventListener("DOMContentLoaded",()=>{var e=document.createElement("script");e.charset="UTF-8",e.src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js",e.async=!1,e.defer=!0,document.head.appendChild(e),e.onload=function(){NexT.utils.fmtBusuanzi()}})</script><title>机器学习中的特征工程 - Patrick's Blog</title><noscript><link rel=stylesheet href=/css/noscript.css></noscript></head><body itemscope itemtype=http://schema.org/WebPage class=use-motion><div class=headband></div><main class=main><header class=header itemscope itemtype=http://schema.org/WPHeader><div class=header-inner><div class=site-brand-container><div class=site-nav-toggle><div class=toggle aria-label role=button><span class=toggle-line></span>
<span class=toggle-line></span>
<span class=toggle-line></span></div></div><div class=site-meta><a href=/ class=brand rel=start><i class=logo-line></i><h1 class=site-title>Patrick's Blog</h1><i class=logo-line></i></a><p class=site-subtitle itemprop=description>Once start, goes forward!</p></div><div class=site-nav-right><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class=site-nav><ul class="main-menu menu"><li class="menu-item menu-item-home"><a href=/ class=hvr-icon-pulse rel=section><i class="fa fa-home hvr-icon"></i>首页</a></li><li class="menu-item menu-item-about"><a href=/about/ class=hvr-icon-pulse rel=section><i class="fa fa-user hvr-icon"></i>关于</a></li><li class="menu-item menu-item-flinks"><a href=/flinks.html class=hvr-icon-pulse rel=section><i class="fa fa-thumbs-up hvr-icon"></i>站点示例</a></li><li class="menu-item menu-item-archives"><a href=/archives/ class=hvr-icon-pulse rel=section><i class="fa fa-archive hvr-icon"></i>归档
<span class=badge>33</span></a></li><li class="menu-item menu-item-commonweal"><a href=/404.html class=hvr-icon-pulse rel=section><i class="fa fa-heartbeat hvr-icon"></i>公益 404</a></li><li class="menu-item menu-item-search"><a role=button class="popup-trigger hvr-icon-pulse"><i class="fa fa-search fa-fw hvr-icon"></i>搜索</a></li></ul></nav><div class=search-pop-overlay><div class="popup search-popup"><div class=search-header><span class=search-icon><i class="fa fa-search"></i></span><div class=search-input-container><input autocomplete=off autocapitalize=off maxlength=80 placeholder=搜索... spellcheck=false type=search class=search-input></div><span class=popup-btn-close role=button><i class="fa fa-times-circle"></i></span></div><div class="search-result-container no-result"><div class=search-result-icon><i class="fa fa-spinner fa-pulse fa-5x"></i></div></div></div></div></div><div class="toggle sidebar-toggle" role=button><span class=toggle-line></span>
<span class=toggle-line></span>
<span class=toggle-line></span></div><aside class=sidebar><div class="sidebar-inner sidebar-nav-active sidebar-toc-active"><ul class=sidebar-nav><li class=sidebar-nav-toc>文章目录</li><li class=sidebar-nav-overview>站点概览</li></ul><div class=sidebar-panel-container><div class="post-toc-wrap sidebar-panel"><div class="post-toc animated"><nav id=TableOfContents><ul><li><a href=#概述>概述</a><ul><li><a href=#分类>分类</a></li></ul></li><li><a href=#数据清洗>数据清洗</a><ul><li><a href=#数据样本采集抽样>数据样本采集(抽样)</a></li><li><a href=#缺失值>缺失值</a></li><li><a href=#异常值空值处理>异常值(空值)处理</a></li></ul></li><li><a href=#特征预处理>特征预处理</a><ul><li><a href=#特征选择>特征选择</a></li><li><a href=#特征变换>特征变换</a><ul><li><a href=#对指化>对指化</a></li><li><a href=#离散化>离散化</a></li></ul></li><li><a href=#无量纲化>无量纲化</a><ul><li><a href=#区间缩放对列向量处理>区间缩放(对列向量处理)</a></li><li><a href=#标准化对列向量处理>标准化(对列向量处理)</a></li><li><a href=#归一化对行向量处理>归一化(对行向量处理)</a></li></ul></li><li><a href=#数值化>数值化</a><ul><li><a href=#one-hot-encoding与dummy-encoding>one-hot encoding与dummy encoding</a></li></ul></li><li><a href=#正规化规范化>正规化(规范化)</a></li></ul></li><li><a href=#连续变量压缩>连续变量压缩</a><ul><li><a href=#特征降维>特征降维</a><ul><li><a href=#pca-奇异值分解等线性降维>PCA, 奇异值分解等线性降维</a></li><li><a href=#lda降维>LDA降维</a></li></ul></li></ul></li><li><a href=#分类变量压缩技术>分类变量压缩技术</a><ul><li><a href=#ivinformation-value值与woeweight-of-evidence打分>IV(Information Value)值与WOE(Weight of Evidence)打分</a></li></ul></li><li><a href=#特征衍生>特征衍生</a></li><li><a href=#参考>参考</a></li></ul></nav></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author site-overview-item animated" itemprop=author itemscope itemtype=http://schema.org/Person><img class=site-author-image itemprop=image alt=Patrick src=/imgs/img-lazy-loading.gif data-src=/img/avatar.jpg><p class=site-author-name itemprop=name>Patrick</p><div class=site-description itemprop=description>个人学习笔记</div></div><div class="site-state-wrap site-overview-item animated"><nav class=site-state><div class="site-state-item site-state-posts"><a href=/archives/><span class=site-state-item-count>33</span>
<span class=site-state-item-name>日志</span></a></div><div class="site-state-item site-state-categories"><a href=/categories/><span class=site-state-item-count>4</span>
<span class=site-state-item-name>分类</span></a></div><div class="site-state-item site-state-tags"><a href=/tags/><span class=site-state-item-count>8</span>
<span class=site-state-item-name>标签</span></a></div></nav></div><div class="links-of-social site-overview-item animated"></div><div class="cc-license animated" itemprop=license><a href=https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh class=cc-opacity rel=noopener target=_blank title=共享知识><img src=/imgs/img-lazy-loading.gif data-src=/imgs/cc/big/by_nc_sa.svg alt=共享知识></a></div><div class="links-of-blogroll site-overview-item animated"><div class=links-of-blogroll-title><i class="fa fa-globe fa-fw"></i>
友情链接</div><ul class=links-of-blogroll-list><li class=links-of-blogroll-item><a href=https://gitee.com/hugo-next/hugo-theme-next title=https://gitee.com/hugo-next/hugo-theme-next target=_blank>Hugo-NexT</a></li></ul></div></div></div></div><div id=siteinfo-card-widget class=sidebar-card-widget><div class=item-headline><i class="fas fa-chart-line"></i>
<span>网站资讯</span></div><div class=siteinfo><div class=siteinfo-item><div class=item-name><i class="fa-solid fa-calendar-check"></i>已运行：</div><div class=item-count id=runTimes data-publishdate=2015-04-05T13:57:58+08:00></div></div><div class=siteinfo-item><div class=item-name><i class="fas fa fa-user"></i>总访客数：</div><div class=item-count id=busuanzi_value_site_uv><i class="fa fa-sync fa-spin"></i></div></div><div class=siteinfo-item><div class=item-name><i class="fas fa fa-eye"></i>页面浏览：</div><div class=item-count id=busuanzi_value_site_pv><i class="fa fa-sync fa-spin"></i></div></div><div class=siteinfo-item><div class=item-name><i class="fa fa-font"></i>总字数：</div><div class=item-count id=wordsCount data-count=22332></div></div><div class=siteinfo-item><div class=item-name><i class="fa fa-mug-hot"></i>阅读约：</div><div class=item-count id=readTimes data-times=121></div></div><div class=siteinfo-item><div class=item-name><i class="fa fa-clock-rotate-left"></i>最后更新于：</div><div class=item-count id=last-push-date data-lastpushdate=2023-05-31T21:26:21+08:00></div></div></div></div></aside><div class=sidebar-dimmer></div></header><div class=tool-buttons><div id=goto-gtranslate class=button title=多语言翻译><i class="fas fa-globe"></i></div><div id=toggle-theme class=button title=深浅模式切换><i class="fas fa-adjust"></i></div><div class=back-to-top role=button title=返回顶部><i class="fa fa-arrow-up"></i>
<span>0%</span></div></div><div class=reading-progress-bar></div><a role=button class="book-mark-link book-mark-link-fixed"></a><script type=text/javascript src=//sidecar.gitter.im/dist/sidecar.v1.js async></script><script type=text/javascript>((window.gitter={}).chat={}).options={room:"hugo-next/community"}</script><noscript><div class=noscript-warning>Theme NexT works best with JavaScript enabled</div></noscript><div class="main-inner post posts-expand"><div class=post-block><article itemscope itemtype=http://schema.org/Article class=post-content lang><link itemprop=mainEntityOfPage href=/post/featureenginering-of-machinelearning/><span hidden itemprop=author itemscope itemtype=http://schema.org/Person><meta itemprop=image content="/img/avatar.jpg"><meta itemprop=name content="Patrick"></span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization><meta itemprop=name content="Patrick"><meta itemprop=description content="个人学习笔记"></span><span hidden itemprop=post itemscope itemtype=http://schema.org/CreativeWork><meta itemprop=name content="机器学习中的特征工程"><meta itemprop=description content="featureenginering-of-machinelearning"></span><header class=post-header><h1 class=post-title itemprop="name headline">机器学习中的特征工程
<a href=https://github.com/user-name/repo-name/tree/branch-name/subdirectory-name/post/featureenginering-of-machinelearning.md rel="noopener external nofollow noreferrer" target=_blank class="exturl post-edit-link" title=编辑><i class="fa fa-pen-nib"></i></a></h1><div class=post-meta-container><div class=post-meta-items><span class=post-meta-item><span class=post-meta-item-icon><i class="far fa-calendar"></i>
</span><span class=post-meta-item-text title=发表于>发表于：
</span><time title="创建时间：2020-02-03 15:42:32 +0800 CST" itemprop="dateCreated datePublished" datetime="2020-02-03 15:42:32 +0800 CST">2020-02-03
</time></span><span class=post-meta-item><span class=post-meta-item-icon><i class="far fa-calendar-check"></i>
</span><span class=post-meta-item-text title=更新于>更新于：
</span><time title=修改时间：2024-04-04T11:37:12+08:00 itemprop=dateModified datetime=2024-04-04T11:37:12+08:00>2024-04-04</time>
</span><span class=post-meta-item><span class=post-meta-item-icon><i class="far fa-folder-open"></i>
</span><span class=post-meta-item-text title=分类于>分类于：
</span><span itemprop=about itemscope itemtype=http://schema.org/Thing><a href=/categories/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6 itemprop=url rel=index><span itemprop=name>数据科学</span></a></span></span></div><div class=post-meta-items><span class=post-meta-item title=字数><span class=post-meta-item-icon><i class="far fa-file-word"></i>
</span><span class=post-meta-item-text>字数：</span>
<span>393</span>
</span><span class=post-meta-item title=阅读><span class=post-meta-item-icon><i class="far fa-clock"></i>
</span><span class=post-meta-item-text>阅读：&ap;</span>
<span>2分钟</span>
</span><span class=post-meta-item title=浏览><span class=post-meta-item-icon><i class="far fa-eye"></i>
</span><span class=post-meta-item-text>浏览：
</span><span id=busuanzi_value_page_pv data-path=/post/featureenginering-of-machinelearning/><i class="fa fa-sync fa-spin"></i></span></span></div></div></header><div class="post-body autonumber" itemprop=articleBody><h2 id=概述>概述
<a class=header-anchor href=#%e6%a6%82%e8%bf%b0></a></h2><ul><li>机器学习将数据拟合到数学模型中来获得结论或者做出预测。这些模型吸纳特征作为输入。特征就是原始数据某方面的数学表现。在机器学习流水线中特征位于数据和模型之间。</li><li>特征工程是一项从数据中提取特征，然后转换成适合机器学习模型的格式的艺术。这是机器学习流水线关键的一步，因为正确的特征可以减轻建模的难度，并因此使流水线能输出更高质量的结果。</li><li>数据和特征决定了机器学习的上限, 而模型和算法只是逼近这个上限而已.</li><li>流程:
<img src=/imgs/img-lazy-loading.gif data-src=/img/feature_engineering-1.png alt=img></li></ul><h3 id=分类>分类
<a class=header-anchor href=#%e5%88%86%e7%b1%bb></a></h3><ul><li>特征使用<ul><li>数据选择</li><li>可用性</li></ul></li><li>特征获取<ul><li>特征来源</li><li>特征存储</li></ul></li><li>特征处理<ul><li>数据清洗</li><li>特征预处理</li></ul></li><li>特征监控<ul><li>现有特征</li><li>新特征</li></ul></li></ul><h2 id=数据清洗>数据清洗
<a class=header-anchor href=#%e6%95%b0%e6%8d%ae%e6%b8%85%e6%b4%97></a></h2><h3 id=数据样本采集抽样>数据样本采集(抽样)
<a class=header-anchor href=#%e6%95%b0%e6%8d%ae%e6%a0%b7%e6%9c%ac%e9%87%87%e9%9b%86%e6%8a%bd%e6%a0%b7></a></h3><ul><li>样本要具有代表性</li><li>样本比例要平衡以及样本不平衡时如何处理</li><li>考虑全量数据</li></ul><h3 id=缺失值>缺失值
<a class=header-anchor href=#%e7%bc%ba%e5%a4%b1%e5%80%bc></a></h3><ul><li>缺失值的比例超过50%以上时, 此字段通常舍弃不用, 不做任何填补.</li><li>另一种处理, 将此字段的值根据是否缺失, 生成指示变量, 将原字段舍弃, 并仅使用此指示变量作为输入变量.</li></ul><h3 id=异常值空值处理>异常值(空值)处理
<a class=header-anchor href=#%e5%bc%82%e5%b8%b8%e5%80%bc%e7%a9%ba%e5%80%bc%e5%a4%84%e7%90%86></a></h3><ul><li>识别异常值和重复值<ul><li>Pandas: isnull()/duplicated()</li></ul></li><li>直接丢弃(包括重复值)<ul><li>Pandas: drop()/dropna()/drop_duplicated()</li></ul></li><li>当是否有异常当做一个新的属性, 替代原值<ul><li>Pandas: fillna()</li></ul></li><li>集中值指代: 除异常值以外的均值, 中位数, 众数等<ul><li>Pandas: fillna()</li></ul></li><li>边界值指代: 连续值中使用四分位间距确定的上下边界来确定超过上下边界的数<ul><li>Pandas: fillna()</li></ul></li><li>插值<ul><li>Pandas: interpolate()&ndash;Series</li></ul></li></ul><h2 id=特征预处理>特征预处理
<a class=header-anchor href=#%e7%89%b9%e5%be%81%e9%a2%84%e5%a4%84%e7%90%86></a></h2><ul><li>分类<ul><li>特征选择</li><li>特征变换<ul><li>对数化, 离散化, 数据平滑, 归一化(标准化), 数值化, 正规化</li></ul></li><li>特征降维</li><li>特征衍生</li></ul></li></ul><h3 id=特征选择>特征选择
<a class=header-anchor href=#%e7%89%b9%e5%be%81%e9%80%89%e6%8b%a9></a></h3><ul><li>概述:<ul><li>剔除与标注不相关或者冗余的特征</li></ul></li><li>规约思路:<ul><li>过滤思想<ul><li>离散与连续数据类型处理</li></ul></li><li>包裹思想<ul><li>遍历特征子集</li></ul></li><li>嵌入思想<ul><li>建立简单回归模型</li></ul></li></ul></li></ul><h3 id=特征变换>特征变换
<a class=header-anchor href=#%e7%89%b9%e5%be%81%e5%8f%98%e6%8d%a2></a></h3><h4 id=对指化>对指化
<a class=header-anchor href=#%e5%af%b9%e6%8c%87%e5%8c%96></a></h4><h4 id=离散化>离散化
<a class=header-anchor href=#%e7%a6%bb%e6%95%a3%e5%8c%96></a></h4><ul><li>概述:<ul><li>将连续变量分成几段(bins)</li></ul></li><li>方法:<ul><li>等频</li><li>等距</li><li>自因变量优化</li></ul></li><li>优点:<ul><li>可使数据精简, 降低数据的复杂度, 让数据更容易被解释.</li><li>可支持许多无法处理数值型属性的分类算法, 如贝叶斯分类算法, 以关联规则为基础的分类算法.</li><li>可提高分类器的稳定性, 进而提升分类模型的准确度.</li><li>可找出条件属性在目标属性上的趋势(Trend), 有助于未来的解读.</li></ul></li></ul><h3 id=无量纲化>无量纲化
<a class=header-anchor href=#%e6%97%a0%e9%87%8f%e7%ba%b2%e5%8c%96></a></h3><ul><li>分类: 区间缩放, 标准化和归一化</li><li>使用时机
1、在后续的分类、聚类算法中，需要使用距离来度量相似性的时候、或者使用PCA、LDA这些需要用到协方差分析进行降维的时候，同时数据分布可以近似为正太分布，标准化方法(Z-score standardization)表现更好.
2. 在不涉及距离度量、协方差计算、数据不符合正太分布的时候，可以使用区间缩放法或其他归一化方法。比如图像处理中，将RGB图像转换为灰度图像后将其值限定在[0 255]的范围.</li></ul><h4 id=区间缩放对列向量处理>区间缩放(对列向量处理)
<a class=header-anchor href=#%e5%8c%ba%e9%97%b4%e7%bc%a9%e6%94%be%e5%af%b9%e5%88%97%e5%90%91%e9%87%8f%e5%a4%84%e7%90%86></a></h4><ul><li>Min-Max<ul><li>数据缩放到(0,1)之间
$$x&rsquo; = \frac{x - x_{\min}}{x_{\max} - x_{\min}}$$</li></ul></li><li>示例</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.preprocessing <span style=color:#f92672>import</span> MinMaxScaler
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 归一化</span>
</span></span><span style=display:flex><span>MinMaxScaler()<span style=color:#f92672>.</span>fit_transform(np<span style=color:#f92672>.</span>array([<span style=color:#ae81ff>1</span>,<span style=color:#ae81ff>4</span>,<span style=color:#ae81ff>10</span>,<span style=color:#ae81ff>15</span>,<span style=color:#ae81ff>21</span>])<span style=color:#f92672>.</span>reshape(<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>,<span style=color:#ae81ff>1</span>))
</span></span><span style=display:flex><span><span style=color:#75715e># array([[0.  ],</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#        [0.15],</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#        [0.45],</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#        [0.7 ],</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#        [1.  ]])</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>MinMaxScaler()<span style=color:#f92672>.</span>inverse_transform(result) <span style=color:#75715e># 将归一化后的结果逆转</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 当X中特征太多时, 使用partial_fit作为训练接口</span>
</span></span></code></pre></div><h4 id=标准化对列向量处理>标准化(对列向量处理)
<a class=header-anchor href=#%e6%a0%87%e5%87%86%e5%8c%96%e5%af%b9%e5%88%97%e5%90%91%e9%87%8f%e5%a4%84%e7%90%86></a></h4><ul><li>标准化的前提是特征值服从正态分布，标准化后，其转换成标准正态分布。</li><li>Z-score
$$x&rsquo;= \frac{x - \bar{x}}{\sigma}$$</li><li>示例</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.preprocessing <span style=color:#f92672>import</span> StandardScaler
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 标注化</span>
</span></span><span style=display:flex><span>StandardScaler()<span style=color:#f92672>.</span>fit_transform(np<span style=color:#f92672>.</span>array([<span style=color:#ae81ff>1</span>,<span style=color:#ae81ff>1</span>,<span style=color:#ae81ff>1</span>,<span style=color:#ae81ff>1</span>,<span style=color:#ae81ff>0</span>,<span style=color:#ae81ff>0</span>,<span style=color:#ae81ff>0</span>,<span style=color:#ae81ff>0</span>])<span style=color:#f92672>.</span>reshape(<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>,<span style=color:#ae81ff>1</span>))
</span></span><span style=display:flex><span><span style=color:#75715e># array([[ 1.],</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#        [ 1.],</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#        [ 1.],</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#        [ 1.],</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#        [-1.],</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#        [-1.],</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#        [-1.],</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#        [-1.]])</span>
</span></span></code></pre></div><h4 id=归一化对行向量处理>归一化(对行向量处理)
<a class=header-anchor href=#%e5%bd%92%e4%b8%80%e5%8c%96%e5%af%b9%e8%a1%8c%e5%90%91%e9%87%8f%e5%a4%84%e7%90%86></a></h4><ul><li>归一化目的在于样本向量在点乘运算或其他核函数计算相似性时，拥有统一的标准，也就是说都转化为“单位向量”.</li><li>公式
$$x&rsquo;= \frac{x_{i}}{\sqrt{\sum_{j=1}^{n} |x_{j}|^{2}}}$$</li><li>示例</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.datasets <span style=color:#f92672>import</span> load_iris
</span></span><span style=display:flex><span><span style=color:#75715e>#导入IRIS数据集</span>
</span></span><span style=display:flex><span>iris <span style=color:#f92672>=</span> load_iris()
</span></span><span style=display:flex><span><span style=color:#75715e>#特征矩阵</span>
</span></span><span style=display:flex><span>iris<span style=color:#f92672>.</span>data
</span></span><span style=display:flex><span><span style=color:#75715e>#目标向量</span>
</span></span><span style=display:flex><span>iris<span style=color:#f92672>.</span>target
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.preprocessing <span style=color:#f92672>import</span> Normalizer
</span></span><span style=display:flex><span><span style=color:#75715e>#归一化，返回值为归一化后的数据</span>
</span></span><span style=display:flex><span>Normalizer()<span style=color:#f92672>.</span>fit_transform(iris<span style=color:#f92672>.</span>data)
</span></span></code></pre></div><h3 id=数值化>数值化
<a class=header-anchor href=#%e6%95%b0%e5%80%bc%e5%8c%96></a></h3><ul><li>数据分类:<ul><li>定类: 数值化-独热(One-Hot Encode)</li><li>定序: 数值化-标签化</li><li>定距: 归一化</li><li>定比</li></ul></li><li>示例</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 使用pandas</span>
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> pandas <span style=color:#66d9ef>as</span> pd
</span></span><span style=display:flex><span><span style=color:#75715e># onehot_cols 为需要进行哑变量的数组列</span>
</span></span><span style=display:flex><span>pd<span style=color:#f92672>.</span>get_dummies(whole_df[onehot_cols], dummy_na <span style=color:#f92672>=</span> <span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 使用sklearn</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.preprocessing <span style=color:#f92672>import</span> LabelEncoder,OneHotEncoder
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>LabelEncoder()<span style=color:#f92672>.</span>fit_transform(np<span style=color:#f92672>.</span>array([<span style=color:#e6db74>&#34;Down&#34;</span>, <span style=color:#e6db74>&#34;Up&#34;</span>, <span style=color:#e6db74>&#34;Up&#34;</span>, <span style=color:#e6db74>&#34;Down&#34;</span>])<span style=color:#f92672>.</span>reshape(<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>,<span style=color:#ae81ff>1</span>))
</span></span><span style=display:flex><span><span style=color:#75715e># array([0, 1, 1, 0])</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>lb_encoder <span style=color:#f92672>=</span> LabelEncoder()
</span></span><span style=display:flex><span>lb_tran <span style=color:#f92672>=</span> lb_encoder<span style=color:#f92672>.</span>fit_transform(np<span style=color:#f92672>.</span>array([<span style=color:#e6db74>&#34;Red&#34;</span>, <span style=color:#e6db74>&#34;Yellow&#34;</span>, <span style=color:#e6db74>&#34;Blue&#34;</span>, <span style=color:#e6db74>&#34;Green&#34;</span>]))
</span></span><span style=display:flex><span>oht_encoder <span style=color:#f92672>=</span> OneHotEncoder()<span style=color:#f92672>.</span>fit(lb_tran<span style=color:#f92672>.</span>reshape(<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>,<span style=color:#ae81ff>1</span>))
</span></span><span style=display:flex><span>oht_encoder<span style=color:#f92672>.</span>transform(lb_encoder<span style=color:#f92672>.</span>transform(np<span style=color:#f92672>.</span>array([<span style=color:#e6db74>&#34;Yellow&#34;</span>, <span style=color:#e6db74>&#34;Blue&#34;</span>, <span style=color:#e6db74>&#34;Green&#34;</span>, <span style=color:#e6db74>&#34;Green&#34;</span>, <span style=color:#e6db74>&#34;Red&#34;</span>]))<span style=color:#f92672>.</span>reshape(<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>,<span style=color:#ae81ff>1</span>))
</span></span><span style=display:flex><span>oht_encoder<span style=color:#f92672>.</span>transform(lb_encoder<span style=color:#f92672>.</span>transform(np<span style=color:#f92672>.</span>array([<span style=color:#e6db74>&#34;Yellow&#34;</span>, <span style=color:#e6db74>&#34;Blue&#34;</span>, <span style=color:#e6db74>&#34;Green&#34;</span>, <span style=color:#e6db74>&#34;Green&#34;</span>, <span style=color:#e6db74>&#34;Red&#34;</span>]))<span style=color:#f92672>.</span>reshape(<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>,<span style=color:#ae81ff>1</span>))<span style=color:#f92672>.</span>toarray()
</span></span><span style=display:flex><span><span style=color:#75715e># array([[0., 0., 0., 1.],</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#        [1., 0., 0., 0.],</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#        [0., 1., 0., 0.],</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#        [0., 1., 0., 0.],</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#        [0., 0., 1., 0.]])</span>
</span></span></code></pre></div><h4 id=one-hot-encoding与dummy-encoding>one-hot encoding与dummy encoding
<a class=header-anchor href=#one-hot-encoding%e4%b8%8edummy-encoding></a></h4><ul><li>one-hot encoding: 将离散型特征的每一种取值都看成一种状态，若你的这一特征中有N个不相同的取值，那么我们就可以将该特征抽象成N种不同的状态，one-hot编码保证了每一个取值只会使得一种状态处于“激活态”，也就是说这N种状态中只有一个状态位值为1，其他状态位都是0。</li><li>dummy encoding: 任意的将一个状态位去除。</li><li>最好是选择正则化 + one-hot编码；哑变量编码也可以使用，不过最好选择前者。虽然哑变量可以去除one-hot编码的冗余信息，但是因为每个离散型特征各个取值的地位都是对等的，随意取舍未免来的太随意。</li></ul><h3 id=正规化规范化>正规化(规范化)
<a class=header-anchor href=#%e6%ad%a3%e8%a7%84%e5%8c%96%e8%a7%84%e8%8c%83%e5%8c%96></a></h3><ul><li>常用<ul><li>L1距离:
$$x&rsquo;= \frac{x_i}{\sum_{j=1}^n|x_j|}$$</li><li>L2距离:
$$x&rsquo;= \frac{x_i}{\sqrt{\sum_{j=1}^n|x_j|^2}}$$</li></ul></li><li>场景:<ol><li>直接用在特征上(比较少)</li><li>用在每个对象的各个特征的表示(特征矩阵的行)</li><li>模型的参数上(回归模型使用较多)</li></ol></li><li>示例</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.preprocessing <span style=color:#f92672>import</span> Normalizer
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># L1距离</span>
</span></span><span style=display:flex><span>Normalizer(norm<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;l1&#39;</span>)<span style=color:#f92672>.</span>fit_transform(np<span style=color:#f92672>.</span>array([<span style=color:#ae81ff>1</span>,<span style=color:#ae81ff>1</span>,<span style=color:#ae81ff>3</span>,<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>,<span style=color:#ae81ff>2</span>])<span style=color:#f92672>.</span>reshape(<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>,<span style=color:#ae81ff>1</span>))
</span></span><span style=display:flex><span><span style=color:#75715e># array([[ 1.],</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#        [ 1.],</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#        [ 1.],</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#        [-1.],</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#        [ 1.]])</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># L2距离</span>
</span></span><span style=display:flex><span>Normalizer(norm<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;l2&#39;</span>)<span style=color:#f92672>.</span>fit_transform(np<span style=color:#f92672>.</span>array([[<span style=color:#ae81ff>1</span>,<span style=color:#ae81ff>1</span>,<span style=color:#ae81ff>3</span>,<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>,<span style=color:#ae81ff>2</span>]]))
</span></span><span style=display:flex><span><span style=color:#75715e># array([[ 0.25,  0.25,  0.75, -0.25,  0.5 ]])</span>
</span></span></code></pre></div><h2 id=连续变量压缩>连续变量压缩
<a class=header-anchor href=#%e8%bf%9e%e7%bb%ad%e5%8f%98%e9%87%8f%e5%8e%8b%e7%bc%a9></a></h2><ul><li>主成分分析, 因子分析, 变量聚类</li></ul><h3 id=特征降维>特征降维
<a class=header-anchor href=#%e7%89%b9%e5%be%81%e9%99%8d%e7%bb%b4></a></h3><h4 id=pca-奇异值分解等线性降维>PCA, 奇异值分解等线性降维
<a class=header-anchor href=#pca-%e5%a5%87%e5%bc%82%e5%80%bc%e5%88%86%e8%a7%a3%e7%ad%89%e7%ba%bf%e6%80%a7%e9%99%8d%e7%bb%b4></a></h4><ul><li>PCA:<ul><li>求特征协方差矩阵</li><li>求协方差的特征值和特征向量</li><li>将特征值按照大小排序, 选择其中最大的k个</li><li>将样本点投影到选取的特征向量上</li></ul></li></ul><h4 id=lda降维>LDA降维
<a class=header-anchor href=#lda%e9%99%8d%e7%bb%b4></a></h4><ul><li>概述<ul><li>线性判别式分析(Liner Discriminant Analysis)</li></ul></li><li>核心思想:<ul><li>投影变化后同一标注内距离尽可能小</li><li>不同标注间距离尽可能大</li></ul></li></ul><h2 id=分类变量压缩技术>分类变量压缩技术
<a class=header-anchor href=#%e5%88%86%e7%b1%bb%e5%8f%98%e9%87%8f%e5%8e%8b%e7%bc%a9%e6%8a%80%e6%9c%af></a></h2><ul><li>水平聚类, WOE打分</li></ul><h3 id=ivinformation-value值与woeweight-of-evidence打分>IV(Information Value)值与WOE(Weight of Evidence)打分
<a class=header-anchor href=#ivinformation-value%e5%80%bc%e4%b8%8ewoeweight-of-evidence%e6%89%93%e5%88%86></a></h3><h2 id=特征衍生>特征衍生
<a class=header-anchor href=#%e7%89%b9%e5%be%81%e8%a1%8d%e7%94%9f></a></h2><ul><li>常用方法:<ul><li>四则运算: 加减乘除</li><li>求导与高阶求导</li><li>人工归纳</li></ul></li></ul><h2 id=参考>参考
<a class=header-anchor href=#%e5%8f%82%e8%80%83></a></h2><ul><li><a href=https://github.com/alicezheng/feature-engineering-book title=feature-engineering-book rel="noopener external nofollow noreferrer" target=_blank class=exturl>feature-engineering-book
<i class="fa fa-external-link-alt"></i></a></li></ul></div><footer class=post-footer><div class=post-tags><a href=/tags/%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0>机器学习</a></div><div class=addthis_inline_share_toolbox style=text-align:center></div><hr><div class=post-copyright><img src=/imgs/cc/cc.svg width=75 height=75 align=right alt=共享知识><ul><li class=post-copyright-title><strong>文章标题：</strong>
机器学习中的特征工程</li><li class=post-copyright-author><strong>本文作者： </strong>Patrick</li><li class=post-copyright-link><strong>本文链接：</strong>
<a id=post-cr-link href=/post/featureenginering-of-machinelearning/ title=机器学习中的特征工程>/post/featureenginering-of-machinelearning/</a></li><li class=post-copyright-license><strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <i class="fab fa-fw fa-creative-commons"></i><a target=_blank href=https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh>BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div><div class=post-nav><div class="post-nav-next post-nav-item"><a href=/post/anova-by-python/ rel=next title=单双因素方差分析及Python实现><i class="fa fa-chevron-left"></i> 单双因素方差分析及Python实现</a></div><div class="post-nav-prev post-nav-item"><a href=/post/evaluation-of-machinelearning/ rel=prev title=机器学习中的评估指标>机器学习中的评估指标
<i class="fa fa-chevron-right"></i></a></div></div></footer></article></div></div></main><footer class=footer><div class=footer-inner><div id=gtranslate class=google-translate><i class="fa fa-language"></i><div id=google_translate_element></div></div><div class=copyright>&copy;
<span itemprop=copyrightYear>2015 - 2024
</span><span class=with-love><i class="fa fa-heart"></i>
</span><span class=author itemprop=copyrightHolder>Patrick</span></div><div class=powered-by>由 <a href=https://gohugo.io title=0.121.1 target=_blank>Hugo</a> & <a href=https://github.com/hugo-next/hugo-theme-next title=4.5.3 target=_blank>Hugo NexT.Gemini</a> 强力驱动</div></div></footer><script type=text/javascript src=https://cdn.staticfile.org/animejs/3.2.1/anime.min.js defer></script><script type=text/javascript src=https://cdn.staticfile.org/viewerjs/1.11.0/viewer.min.js defer></script><script class=next-config data-name=main type=application/json>{"bookmark":{"color":"#222","enable":true,"save":"manual"},"copybtn":true,"darkmode":true,"giscus":{"cfg":{"category":"Comments","categoryid":null,"emit":false,"inputposition":"top","mapping":"title","reactions":false,"repo":"username/repo-name","repoid":null,"theme":"preferred_color_scheme"},"js":"https://giscus.app/client.js"},"hostname":"/","i18n":{"ds_day":" 天前","ds_days":" 天 ","ds_hour":" 小时前","ds_hours":" 小时 ","ds_just":"刚刚","ds_min":" 分钟前","ds_mins":" 分钟","ds_month":" 个月前","ds_years":" 年 ","empty":"没有找到任何搜索结果：${query}","hits":"找到 ${hits} 个搜索结果","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","placeholder":"搜索..."},"lang":"zh-CN","lazyload":false,"localSearch":{"enable":true,"limit":1e3,"path":"/searchindexes.xml","preload":false,"topnperarticle":-1,"trigger":"auto","unescape":false},"motion":{"async":true,"enable":true,"transition":{"collheader":"fadeInLeft","postblock":"fadeIn","postbody":"fadeInDown","postheader":"fadeInDown","sidebar":"fadeInUp"}},"postmeta":{"comments":{"enable":true,"plugin":"waline"},"views":{"enable":true,"plugin":"busuanzi"}},"root":"/","scheme":"Gemini","sidebar":{"display":"post","offset":12,"padding":18,"position":"left","width":256},"vendor":{"plugins":"qiniu","router":"https://cdn.staticfile.org"},"version":"4.5.3","waline":{"cfg":{"emoji":false,"imguploader":false,"placeholder":"请文明发言哟 ヾ(≧▽≦*)o","reaction":true,"reactiontext":["点赞","踩一下","得意","不屑","尴尬","睡觉"],"reactiontitle":"你认为这篇文章怎么样？","requiredmeta":["nick","mail"],"serverurl":null,"sofa":"快来发表你的意见吧 (≧∀≦)ゞ","wordlimit":200},"css":{"alias":"waline","file":"dist/waline.css","name":"@waline/client","version":"2.13.0"},"js":{"alias":"waline","file":"dist/waline.js","name":"@waline/client","version":"2.13.0"}}}</script><script type=text/javascript src=/js/main.min.b0c78e5a4df586ee46d02716ffa91a4a322e56763e04e91eb2ba052c9469ed02.js defer></script><script type=text/javascript src=/js/math.min.a6ada19a368d85dad9ead2040d86ae561a867fafef89391d1aa2aa5909366509.js defer></script></body></html>