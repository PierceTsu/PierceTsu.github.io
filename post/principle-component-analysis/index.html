<!doctype html><html lang=zh-CN data-theme=dark><head><meta charset=UTF-8><meta name=viewport content="width=device-width"><meta name=theme-color content="#222" media="(prefers-color-scheme: dark)"><meta name=generator content="Hugo 0.121.1"><link rel="shortcut icon" type=image/x-icon href=/imgs/icons/favicon.ico><link rel=icon type=image/x-icon href=/imgs/icons/favicon.ico><link rel=icon type=image/png sizes=16x16 href=/imgs/icons/favicon_16x16_next.png><link rel=icon type=image/png sizes=32x32 href=/imgs/icons/favicon_32_32_next.png><link rel=apple-touch-icon sizes=180x180 href=/imgs/icons/apple_touch_icon_next.png><meta itemprop=name content="多元统计之主成分分析"><meta itemprop=description content="principle-component-analysis"><meta itemprop=datePublished zgotmplz><meta itemprop=dateModified zgotmplz><meta itemprop=image content="/img/avatar.jpg"><meta itemprop=keywords content="数理统计"><meta property="og:type" content="article"><meta property="og:title" content="多元统计之主成分分析"><meta property="og:description" content="principle-component-analysis"><meta property="og:image" content="/img/avatar.jpg"><meta property="og:image:width" content="312"><meta property="og:image:height" content="312"><meta property="og:image:type" content="image/jpeg/png/svg/jpg"><meta property="og:url" content="/post/principle-component-analysis/"><meta property="og:site_name" content="Patrick's Blog"><meta property="og:locale" content="zh-CN"><meta property="article:author" content="Patrick"><meta property="article:published_time" content="2019-03-02 11:55:02 +0800 CST"><meta property="article:modified_time" content="2024-04-04 09:43:02 +0800 CST"><link type=text/css rel=stylesheet href=https://cdn.bootcdn.net/ajax/libs/font-awesome/6.1.2/css/all.min.css><link type=text/css rel=stylesheet href=https://cdn.bootcdn.net/ajax/libs/animate.css/3.1.1/animate.min.css><link type=text/css rel=stylesheet href=https://cdn.bootcdn.net/ajax/libs/viewerjs/1.11.0/viewer.min.css><link rel=stylesheet href=/css/main.min.a987c3fbca3727259a25c99140afed885cbffe7b77dba717d89bbe0780afcd01.css><style type=text/css>.post-footer,.flinks-list-footer hr:after{content:"~ 我可是有底线的哟 ~"}</style><script type=text/javascript>(function(){localDB={set:function(e,t,n){if(n===0)return;const s=new Date,o=n*864e5,i={value:t,expiry:s.getTime()+o};localStorage.setItem(e,JSON.stringify(i))},get:function(e){const t=localStorage.getItem(e);if(!t)return void 0;const n=JSON.parse(t),s=new Date;return s.getTime()>n.expiry?(localStorage.removeItem(e),void 0):n.value}},theme={active:function(){const e=localDB.get("theme");if(e==null)return;theme.toggle(e),window.matchMedia("(prefers-color-scheme: dark)").addListener(function(e){theme.toggle(e.matches?"dark":"light")})},toggle:function(e){document.documentElement.setAttribute("data-theme",e),localDB.set("theme",e,2);const t=document.querySelector("iframe.giscus-frame");if(t){const n={setConfig:{theme:e}};t.contentWindow.postMessage({giscus:n},"https://giscus.app")}}},theme.active()})(window)</script><script class=next-config data-name=page type=application/json>{"comments":false,"isHome":false,"isPage":true,"math":{"css":{"file":"dist/katex.min.css","name":"katex","version":"0.16.0"},"js":[{"file":"dist/katex.min.js","name":"katex","version":"0.16.0"},{"alias_name":"katex","file":"dist/contrib/auto-render.min.js","name":"auto-render","version":"0.16.0"}],"render":"katex"},"path":"principle-component-analysis","permalink":"/post/principle-component-analysis/","title":"多元统计之主成分分析","waline":{"js":[{"alias":"waline","alias_name":"@waline/client","file":"dist/pageview.js","name":"pageview","version":"2.13.0"},{"alias":"waline","alias_name":"@waline/client","file":"dist/comment.js","name":"comment","version":"2.13.0"}]}}</script><script type=text/javascript>document.addEventListener("DOMContentLoaded",()=>{var e=document.createElement("script");e.charset="UTF-8",e.src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js",e.async=!1,e.defer=!0,document.head.appendChild(e),e.onload=function(){NexT.utils.fmtBusuanzi()}})</script><title>多元统计之主成分分析 - Patrick's Blog</title><noscript><link rel=stylesheet href=/css/noscript.css></noscript></head><body itemscope itemtype=http://schema.org/WebPage class=use-motion><div class=headband></div><main class=main><header class=header itemscope itemtype=http://schema.org/WPHeader><div class=header-inner><div class=site-brand-container><div class=site-nav-toggle><div class=toggle aria-label role=button><span class=toggle-line></span>
<span class=toggle-line></span>
<span class=toggle-line></span></div></div><div class=site-meta><a href=/ class=brand rel=start><i class=logo-line></i><h1 class=site-title>Patrick's Blog</h1><i class=logo-line></i></a><p class=site-subtitle itemprop=description>Once start, goes forward!</p></div><div class=site-nav-right><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class=site-nav><ul class="main-menu menu"><li class="menu-item menu-item-home"><a href=/ class=hvr-icon-pulse rel=section><i class="fa fa-home hvr-icon"></i>首页</a></li><li class="menu-item menu-item-about"><a href=/about/ class=hvr-icon-pulse rel=section><i class="fa fa-user hvr-icon"></i>关于</a></li><li class="menu-item menu-item-flinks"><a href=/flinks.html class=hvr-icon-pulse rel=section><i class="fa fa-thumbs-up hvr-icon"></i>站点示例</a></li><li class="menu-item menu-item-archives"><a href=/archives/ class=hvr-icon-pulse rel=section><i class="fa fa-archive hvr-icon"></i>归档
<span class=badge>33</span></a></li><li class="menu-item menu-item-commonweal"><a href=/404.html class=hvr-icon-pulse rel=section><i class="fa fa-heartbeat hvr-icon"></i>公益 404</a></li><li class="menu-item menu-item-search"><a role=button class="popup-trigger hvr-icon-pulse"><i class="fa fa-search fa-fw hvr-icon"></i>搜索</a></li></ul></nav><div class=search-pop-overlay><div class="popup search-popup"><div class=search-header><span class=search-icon><i class="fa fa-search"></i></span><div class=search-input-container><input autocomplete=off autocapitalize=off maxlength=80 placeholder=搜索... spellcheck=false type=search class=search-input></div><span class=popup-btn-close role=button><i class="fa fa-times-circle"></i></span></div><div class="search-result-container no-result"><div class=search-result-icon><i class="fa fa-spinner fa-pulse fa-5x"></i></div></div></div></div></div><div class="toggle sidebar-toggle" role=button><span class=toggle-line></span>
<span class=toggle-line></span>
<span class=toggle-line></span></div><aside class=sidebar><div class="sidebar-inner sidebar-nav-active sidebar-toc-active"><ul class=sidebar-nav><li class=sidebar-nav-toc>文章目录</li><li class=sidebar-nav-overview>站点概览</li></ul><div class=sidebar-panel-container><div class="post-toc-wrap sidebar-panel"><div class="post-toc animated"><nav id=TableOfContents><ul><li><a href=#概述>概述</a><ul><li><a href=#几何意义>几何意义</a></li><li><a href=#数学推导>数学推导</a></li><li><a href=#性质>性质</a><ul><li><a href=#性质一>性质一</a></li><li><a href=#性质二>性质二</a></li><li><a href=#性质三>性质三</a></li><li><a href=#性质四>性质四</a></li></ul></li></ul></li><li><a href=#主成分的偏差贡献率与信息提取率>主成分的偏差贡献率与信息提取率</a><ul><li><a href=#主成分的偏差贡献率>主成分的偏差贡献率</a></li><li><a href=#信息提取率>信息提取率</a></li></ul></li><li><a href=#实际应用>实际应用</a><ul><li><a href=#出发点>出发点</a><ul><li><a href=#标准化的实质>标准化的实质</a></li><li><a href=#注意>注意</a></li><li><a href=#步骤>步骤</a></li></ul></li><li><a href=#综合评价>综合评价</a><ul><li><a href=#主成分得分>主成分得分</a></li></ul></li><li><a href=#r应用>R应用</a></li></ul></li><li><a href=#主成分回归pcr>主成分回归(PCR)</a><ul><li><a href=#多元线性回归>多元线性回归</a></li><li><a href=#主成分回归的原理>主成分回归的原理</a></li></ul></li></ul></nav></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author site-overview-item animated" itemprop=author itemscope itemtype=http://schema.org/Person><img class=site-author-image itemprop=image alt=Patrick src=/imgs/img-lazy-loading.gif data-src=/img/avatar.jpg><p class=site-author-name itemprop=name>Patrick</p><div class=site-description itemprop=description>个人学习笔记</div></div><div class="site-state-wrap site-overview-item animated"><nav class=site-state><div class="site-state-item site-state-posts"><a href=/archives/><span class=site-state-item-count>33</span>
<span class=site-state-item-name>日志</span></a></div><div class="site-state-item site-state-categories"><a href=/categories/><span class=site-state-item-count>4</span>
<span class=site-state-item-name>分类</span></a></div><div class="site-state-item site-state-tags"><a href=/tags/><span class=site-state-item-count>8</span>
<span class=site-state-item-name>标签</span></a></div></nav></div><div class="links-of-social site-overview-item animated"></div><div class="cc-license animated" itemprop=license><a href=https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh class=cc-opacity rel=noopener target=_blank title=共享知识><img src=/imgs/img-lazy-loading.gif data-src=/imgs/cc/big/by_nc_sa.svg alt=共享知识></a></div><div class="links-of-blogroll site-overview-item animated"><div class=links-of-blogroll-title><i class="fa fa-globe fa-fw"></i>
友情链接</div><ul class=links-of-blogroll-list><li class=links-of-blogroll-item><a href=https://gitee.com/hugo-next/hugo-theme-next title=https://gitee.com/hugo-next/hugo-theme-next target=_blank>Hugo-NexT</a></li></ul></div></div></div></div><div id=siteinfo-card-widget class=sidebar-card-widget><div class=item-headline><i class="fas fa-chart-line"></i>
<span>网站资讯</span></div><div class=siteinfo><div class=siteinfo-item><div class=item-name><i class="fa-solid fa-calendar-check"></i>已运行：</div><div class=item-count id=runTimes data-publishdate=2015-04-05T13:57:58+08:00></div></div><div class=siteinfo-item><div class=item-name><i class="fas fa fa-user"></i>总访客数：</div><div class=item-count id=busuanzi_value_site_uv><i class="fa fa-sync fa-spin"></i></div></div><div class=siteinfo-item><div class=item-name><i class="fas fa fa-eye"></i>页面浏览：</div><div class=item-count id=busuanzi_value_site_pv><i class="fa fa-sync fa-spin"></i></div></div><div class=siteinfo-item><div class=item-name><i class="fa fa-font"></i>总字数：</div><div class=item-count id=wordsCount data-count=22332></div></div><div class=siteinfo-item><div class=item-name><i class="fa fa-mug-hot"></i>阅读约：</div><div class=item-count id=readTimes data-times=121></div></div><div class=siteinfo-item><div class=item-name><i class="fa fa-clock-rotate-left"></i>最后更新于：</div><div class=item-count id=last-push-date data-lastpushdate=2023-05-31T21:26:21+08:00></div></div></div></div></aside><div class=sidebar-dimmer></div></header><div class=tool-buttons><div id=goto-gtranslate class=button title=多语言翻译><i class="fas fa-globe"></i></div><div id=toggle-theme class=button title=深浅模式切换><i class="fas fa-adjust"></i></div><div class=back-to-top role=button title=返回顶部><i class="fa fa-arrow-up"></i>
<span>0%</span></div></div><div class=reading-progress-bar></div><a role=button class="book-mark-link book-mark-link-fixed"></a><script type=text/javascript src=//sidecar.gitter.im/dist/sidecar.v1.js async></script><script type=text/javascript>((window.gitter={}).chat={}).options={room:"hugo-next/community"}</script><noscript><div class=noscript-warning>Theme NexT works best with JavaScript enabled</div></noscript><div class="main-inner post posts-expand"><div class=post-block><article itemscope itemtype=http://schema.org/Article class=post-content lang><link itemprop=mainEntityOfPage href=/post/principle-component-analysis/><span hidden itemprop=author itemscope itemtype=http://schema.org/Person><meta itemprop=image content="/img/avatar.jpg"><meta itemprop=name content="Patrick"></span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization><meta itemprop=name content="Patrick"><meta itemprop=description content="个人学习笔记"></span><span hidden itemprop=post itemscope itemtype=http://schema.org/CreativeWork><meta itemprop=name content="多元统计之主成分分析"><meta itemprop=description content="principle-component-analysis"></span><header class=post-header><h1 class=post-title itemprop="name headline">多元统计之主成分分析
<a href=https://github.com/user-name/repo-name/tree/branch-name/subdirectory-name/post/principle-component-analysis.md rel="noopener external nofollow noreferrer" target=_blank class="exturl post-edit-link" title=编辑><i class="fa fa-pen-nib"></i></a></h1><div class=post-meta-container><div class=post-meta-items><span class=post-meta-item><span class=post-meta-item-icon><i class="far fa-calendar"></i>
</span><span class=post-meta-item-text title=发表于>发表于：
</span><time title="创建时间：2019-03-02 11:55:02 +0800 CST" itemprop="dateCreated datePublished" datetime="2019-03-02 11:55:02 +0800 CST">2019-03-02
</time></span><span class=post-meta-item><span class=post-meta-item-icon><i class="far fa-calendar-check"></i>
</span><span class=post-meta-item-text title=更新于>更新于：
</span><time title=修改时间：2024-04-04T09:43:02+08:00 itemprop=dateModified datetime=2024-04-04T09:43:02+08:00>2024-04-04</time>
</span><span class=post-meta-item><span class=post-meta-item-icon><i class="far fa-folder-open"></i>
</span><span class=post-meta-item-text title=分类于>分类于：
</span><span itemprop=about itemscope itemtype=http://schema.org/Thing><a href=/categories/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6 itemprop=url rel=index><span itemprop=name>数据科学</span></a></span></span></div><div class=post-meta-items><span class=post-meta-item title=字数><span class=post-meta-item-icon><i class="far fa-file-word"></i>
</span><span class=post-meta-item-text>字数：</span>
<span>897</span>
</span><span class=post-meta-item title=阅读><span class=post-meta-item-icon><i class="far fa-clock"></i>
</span><span class=post-meta-item-text>阅读：&ap;</span>
<span>5分钟</span>
</span><span class=post-meta-item title=浏览><span class=post-meta-item-icon><i class="far fa-eye"></i>
</span><span class=post-meta-item-text>浏览：
</span><span id=busuanzi_value_page_pv data-path=/post/principle-component-analysis/><i class="fa fa-sync fa-spin"></i></span></span></div></div></header><div class="post-body autonumber" itemprop=articleBody><h2 id=概述>概述
<a class=header-anchor href=#%e6%a6%82%e8%bf%b0></a></h2><ul><li>主成分分析就是设法将原来指标重新组合成一组新的互相无关的几个综合指标来代替原来指标, 同时根据实际需要从中取几个较少的综合指标尽可能多地反映原来指标的信息。</li><li>这种将多个指标转化为少数互相无关的综合指标的统计方法叫做主成分分析或称主分量分析。</li></ul><h3 id=几何意义>几何意义
<a class=header-anchor href=#%e5%87%a0%e4%bd%95%e6%84%8f%e4%b9%89></a></h3><ul><li>代数观点:<ul><li>p个原始变量的一些特殊的线性组合</li></ul></li><li>几何意义:<ul><li>这些线性组合通过把由$X_1,X_2,\cdots,X_p$构成的坐标系旋转而产生的新坐标系。这样的新坐标轴使其通过样本变差最大的方向(或者说具有最大的样本方差)。</li></ul></li></ul><h3 id=数学推导>数学推导
<a class=header-anchor href=#%e6%95%b0%e5%ad%a6%e6%8e%a8%e5%af%bc></a></h3><ul><li>设$X = (X_1,\cdots,X_p)&rsquo;$为一个p维随机向量, 并假定存在二阶矩, 其均值向量与协差阵分别记为:
$$\mu = E(X), \quad \Sigma = D(X)$$
考虑如下线性变换<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>$$
</span></span><span style=display:flex><span>\begin{cases}
</span></span><span style=display:flex><span>    Y_1 = t_{11}X_1 + t_{12}X_2 + \cdots + t_{1p}X_p = T&#39;_1X  \\
</span></span><span style=display:flex><span>    Y_2 = t_{21}X_1 + t_{22}X_2 + \cdots + t_{2p}X_p = T&#39;_2X  \\
</span></span><span style=display:flex><span>    \cdots \cdots \\
</span></span><span style=display:flex><span>    Y_p = t_{p1}X_1 + t_{p2}X_2 + \cdots + t_{pp}X_p = T&#39;_pX
</span></span><span style=display:flex><span>\end{cases}
</span></span><span style=display:flex><span>$$
</span></span></code></pre></div>用矩阵表示为$Y = (Y_1,Y_2,\cdots,Y_p)&rsquo;$, 其中$Y = T&rsquo;X, T=(T_1,T_2,\cdots,T_p)$
希望找到一组新的变量$Y_1,\cdots,Y_m(m \le p)$, 这组新的变量要求充分地反映原变量$X_1,\cdots,X_p$的信息, 而且相互独立。<br>对于$Y_1,\cdots,Y_m$有<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>$$
</span></span><span style=display:flex><span>D(Y_i) = D(T&#39;_iX) = T&#39;_iD(X)T&#39;&#39;_i = T&#39;_i\Sigma T_i \quad i=1,2,\cdots,m \\
</span></span><span style=display:flex><span>Cov(Y_i,Y_k) = Cov(T&#39;_iX,T&#39;_kX) = T&#39;_iCov(X,X)T&#39;&#39;_k = T&#39;_i\Sigma T_k \quad i,k=1,2,\cdots,m
</span></span><span style=display:flex><span>$$
</span></span></code></pre></div>则问题转化为在新的变量$Y_1,\cdots,Y_m$相互独立的条件下, 求得$T_i$使得$D(Y_i)$达到最大。<br>由于$D(Y_i) = T&rsquo;_i\Sigma T_i$是向量T的增函数, 添加约束条件$T&rsquo;_iT_i=1$(即将线性组合$Y=T&rsquo;X$的系数标准化即单位化), 问题变为在约束条件下求最大的问题。</li><li>第一主成分满足$T&rsquo;_1T_1=1$, 使得$D(Y_1) = T&rsquo;_1\Sigma T_1$达到最大的$Y_1 = T&rsquo;_1X$。</li><li>第二主成分满足$T&rsquo;_2T_2=1, Cov(Y_2,Y_1) = Cov(T&rsquo;_2X, T&rsquo;_1X) = 0$使得$D(Y_2) = T&rsquo;_2\Sigma T_2$达到最大的$Y_2=T&rsquo;_2X$。</li><li>第k主成分满足$T&rsquo;_kT_k=1, Cov(Y_k,Y_i) = Cov(T&rsquo;_kX, T&rsquo;_iX) = 0 \quad (i &lt; k)$使得$D(Y_k) = T&rsquo;_k\Sigma T_k$达到最大的$Y_k = T&rsquo;_kX$。</li><li>求第一主成分, 构造目标函数为:
$$\quad \varphi_1(T_1, \lambda) = T&rsquo;_1\Sigma T_1 - \lambda(T&rsquo;_1T_1 - 1) \tag{1.2-1}$$
求导有:
$$\quad \frac{\partial \varphi_1}{\partial T_1} = 2\Sigma T_1 - 2\lambda T_1 = 0 \tag{1.2-2}$$
即:
$$\quad (\Sigma - \lambda I)T_1 = 0 \tag{1.2-3}$$
两边左乘$T&rsquo;_1$得到:
$$\quad T&rsquo;_1\Sigma T_1 = \lambda \tag{1.2-4}$$
由于X的协方差阵$\Sigma$为非负, 其特征方程(1.2-3)均大于零, 不妨设$\lambda_1 \ge \lambda_2 \ge \cdots \ge \lambda_p \ge 0$。由(1.2-4)知$Y_1$的方差为$\lambda$。那么, $Y_1$的最大方差值为$\lambda_1$, 其相应的单位化特征向量为$T_1$。</li><li>求第二主成分, 由(1.2-2)有$\Sigma T_1 = \lambda T_1,$则$Cov(Y_2,Y_1) = T&rsquo;_2\Sigma T_1 = \lambda T&rsquo;_2T_1$。如果$Y_2$与$Y_1$相互独立, 既有$T&rsquo;_2T_1 = 0$或$T&rsquo;_1T_2 = 0$。构造第二主成分的目标函数, 即
$$\varphi_2(T_2, \lambda, \rho) = T&rsquo;_2\Sigma T_2 - \lambda(T&rsquo;_2T_2 - 1) - 2\rho(T&rsquo;_1T_2)$$
对目标函数求导有:
$$\frac{\partial\varphi_2}{\partial T_2} = 2\Sigma T_2 - 2\lambda T_2 - 2\rho T_1 = 0$$
用$T&rsquo;_1$左乘有$T&rsquo;_1\Sigma T_2 - \lambda T&rsquo;_1T_2 - \rho T&rsquo;_1T_1 = 0$<br>由于$T&rsquo;_1T_2 = 0, T&rsquo;_1\Sigma T_2 = 0$, 那么$\rho T&rsquo;_1T_1 = 0$, 即有$\rho = 0$<br>从而$(\Sigma - \lambda I)T_2 = 0$, 且$T&rsquo;_2\Sigma T_2 = \lambda \quad (1.2-5)$<br>这样说明, 如果X的协差阵$\Sigma$的特征根为$\lambda_1 \ge \lambda_2 \ge \cdots \ge \lambda_p \ge 0$, 由(1.2-5)知$Y_2$的最大方差值为第二大特征根$\lambda_2$, 其相应的单位化的特征向量为$T_2$。</li><li>针对一般情形, 第k主成分应该是在$T&rsquo;_kT_k = 1$且$T&rsquo;_iT_k = 0$或$T&rsquo;_kT_i = 0(i &lt; k)$的条件下, 使得$D(Y_k) = T&rsquo;_k\Sigma T_k$达到最大的$Y_k = T&rsquo;_kX$。构造目标函数为:
$$\varphi_k(T_k, \lambda, \rho_i) = T&rsquo;_k\Sigma T_k - \lambda(T&rsquo;<em>kT_k - 1) - \sum</em>{i=1}^{k-1}\rho_i(T&rsquo;<em>iT_k) \tag{1.2-6}$$
对目标函数求导有:
$$\frac{\partial\varphi_k}{\partial T_k} = 2\Sigma T_k - 2\lambda T_k - 2\sum</em>{i=1}^{k-1}\rho_iT_i = 0 \tag{1.2-7}$$
用$T&rsquo;_k$左乘(1.2-7)有$T&rsquo;_i\Sigma T_k - \lambda T&rsquo;_iT_k - T&rsquo;<em>i(\sum</em>{i=1}^{k-1}\rho_iT_i) = 0$即$\rho_iT&rsquo;_iT_i = 0$, 那么$\rho_i = 0 \quad (i=1,2,\cdots,k-1)$。从而$(\Sigma - \lambda I)T_k = 0 \quad (1.2-8)$而且$T&rsquo;_k\Sigma T_k = \lambda \quad (1.2-8)$<br>对于X的协差阵$\Sigma$的特征根为$\lambda_1 \ge \lambda_2 \ge \cdots \ge \lambda_p \ge 0$, 由(1.2-7)和(1.2-8)知$Y_k$的最大方差值为第k大特征根$\lambda_k$, 其相应的单位化的特征向量为$T_k$。</li><li>综上所述, 设$X = (X_1, \cdots, X_p)$的协差矩阵为$\Sigma$, 其特征根为$\lambda_1 \ge \cdots \ge \lambda_k$, 相应的单位化的特征向量为$T_1,T_2,\cdots,T_p$。那么, 由此所确定的主成分为$Y_1 = T&rsquo;_1X, \cdots, Y_m = T&rsquo;_mX$, 其方差分别为$\Sigma$的特征根。</li></ul><h3 id=性质>性质
<a class=header-anchor href=#%e6%80%a7%e8%b4%a8></a></h3><ul><li>设$Y = (Y_1,Y_2,\cdots,Y_p)&rsquo;$是X的主成分, 由$\Sigma$的所有特征根构成的对角阵为<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>$$ \Lambda = 
</span></span><span style=display:flex><span>\begin{bmatrix}
</span></span><span style=display:flex><span>  \lambda_1 &amp;  &amp; 0 \\
</span></span><span style=display:flex><span>            &amp; \ddots  \\
</span></span><span style=display:flex><span>  0         &amp;  &amp; \lambda_p
</span></span><span style=display:flex><span>\end{bmatrix}
</span></span><span style=display:flex><span>$$
</span></span></code></pre></div>主成分可表示为 $Y = T&rsquo;X$</li></ul><h4 id=性质一>性质一
<a class=header-anchor href=#%e6%80%a7%e8%b4%a8%e4%b8%80></a></h4><ul><li>主成分的协方差矩阵是对角阵</li></ul><h4 id=性质二>性质二
<a class=header-anchor href=#%e6%80%a7%e8%b4%a8%e4%ba%8c></a></h4><ul><li>主成分的总方差等于原始变量的总方差</li></ul><h4 id=性质三>性质三
<a class=header-anchor href=#%e6%80%a7%e8%b4%a8%e4%b8%89></a></h4><ul><li>主成分$Y_k$与原始变量$X_i$的相关系数为:
$$
\rho(Y_k,X_i) = \frac{\sqrt{\lambda_k}}{\sqrt{\sigma_{ii}}}t_{ki} \tag{1.3.3-1}
$$
并称之为因子负荷量(或因子载荷量)</li></ul><h4 id=性质四>性质四
<a class=header-anchor href=#%e6%80%a7%e8%b4%a8%e5%9b%9b></a></h4><p>$$
\sum_{i=1}^p\rho^2(Y_k,X_i)\cdot\sigma_{ii} = \lambda_k \quad (k = 1,2,\cdots,p) \tag{1.3.4-1}
$$</p><h2 id=主成分的偏差贡献率与信息提取率>主成分的偏差贡献率与信息提取率
<a class=header-anchor href=#%e4%b8%bb%e6%88%90%e5%88%86%e7%9a%84%e5%81%8f%e5%b7%ae%e8%b4%a1%e7%8c%ae%e7%8e%87%e4%b8%8e%e4%bf%a1%e6%81%af%e6%8f%90%e5%8f%96%e7%8e%87></a></h2><ul><li>在选取主成分时, 不仅要考虑累计贡献率, 还应考虑信息提取率。</li></ul><h3 id=主成分的偏差贡献率>主成分的偏差贡献率
<a class=header-anchor href=#%e4%b8%bb%e6%88%90%e5%88%86%e7%9a%84%e5%81%8f%e5%b7%ae%e8%b4%a1%e7%8c%ae%e7%8e%87></a></h3><ul><li>称
$$\varphi_k = \lambda_k / \sum_{k=1}^p\lambda_k$$
为第k个主成分$Y_k$的贡献率。第一主成分的贡献率最大, 其他依次减弱。</li><li>若只取$m(&lt;p)$个主成分, 则称
$$\psi_m = \sum_{k=1}^m\lambda_k/\sum_{k=1}^p\lambda_k$$
为主成分$Y_1,\cdots,Y_m$的累计贡献率, 累计贡献率表明$Y_1,\cdots,Y_m$综合$X_1,X_2,\cdots,X_p$的能力。通常取m, 使得累计贡献率达到一个较高的百分数(如85%以上)。</li></ul><h3 id=信息提取率>信息提取率
<a class=header-anchor href=#%e4%bf%a1%e6%81%af%e6%8f%90%e5%8f%96%e7%8e%87></a></h3><ul><li>任一原始变量$X_i$可用主成分表示为:
$$X_i = t_{1i}Y_1 + t_{2i}Y_2 + \cdots + t_{pi}Y_p$$
其中各个主成分之间互不相关, 所以原始变量的$X_i$的方差为:
$$Var(X_i) = t_{1i}^2\lambda_1 + t_{2i}^2\lambda_2 + \cdots + t_{pi}^2\lambda_p = \sum_{j=1}^pt_{ji}^2\lambda_j = \sigma_{ii}$$</li><li>定义比率:
$$\Omega_i = \sum_{j=1}^mt_{ji}^2\lambda_j/\sigma_{ii}$$
为原始变量$X_i$的信息提取率。</li></ul><h2 id=实际应用>实际应用
<a class=header-anchor href=#%e5%ae%9e%e9%99%85%e5%ba%94%e7%94%a8></a></h2><h3 id=出发点>出发点
<a class=header-anchor href=#%e5%87%ba%e5%8f%91%e7%82%b9></a></h3><ul><li>为消除量纲的不同可能带来的一些不合理的影响, 常常需要事先对变量标准化。</li><li>标准化处理, 即令:<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>$$X_i^* = \frac{X_i - E(X_i)}{\sqrt{D(X_i)}} \quad i=1,\cdots,p$$
</span></span></code></pre></div>$<code>$X^* = (X_1^*, \cdots, X_p^*)'$</code>$的协方差矩阵就是X的相关系数矩阵R.</li></ul><h4 id=标准化的实质>标准化的实质
<a class=header-anchor href=#%e6%a0%87%e5%87%86%e5%8c%96%e7%9a%84%e5%ae%9e%e8%b4%a8></a></h4><ul><li>标准化后各原始指标的方差均为1, 抹杀了数据本身离散度的信息。对于同度量或相似量级的变量还是使用原始的协方差求解主成分为宜。</li></ul><h4 id=注意>注意
<a class=header-anchor href=#%e6%b3%a8%e6%84%8f></a></h4><ul><li>若各指标的数量级相差悬殊或者有不同量纲, 较合理做法:<ul><li>使用原始变量的R代替$\Sigma$做主成分分析;</li><li>使用标准化变量的相关矩阵或者协差阵做主成分分析, 二者结果相同。</li></ul></li><li>从原始变量的相关阵求得的主成分与用原始变量的协差阵求得的主成分一般不相同, 有时差异很大。</li></ul><h4 id=步骤>步骤
<a class=header-anchor href=#%e6%ad%a5%e9%aa%a4></a></h4><ol><li>将原始数据标准化</li><li>建立变量的相关系数阵</li><li>求$<code>$R^*$</code>$的特征根为$<code>$\lambda_1^* \ge \cdots \lambda_p^* \ge 0$</code>$, 相应的特征向量为$<code>$T_1^*, T_2^*, \cdots, T_p^*$</code>$</li><li>由累积方差贡献率确定主成分的个数(m), 并写出主成分为: $<code>$Y_i = (T_i^*)'X \quad (i=1,2,\cdots,m)$</code>$</li></ol><h3 id=综合评价>综合评价
<a class=header-anchor href=#%e7%bb%bc%e5%90%88%e8%af%84%e4%bb%b7></a></h3><ul><li>一般在进行综合评价时, 需要给各指标赋予权重, 再进行综合评价。</li><li>如果是用主成分分析进行综合评价, 则在评价前需要给主成分赋予权重, 此时, 可以以方差贡献率作为参考来确定权重。</li><li>设$Y_1,Y_2,\cdots,Y_p$是所求出的p个主成分, 它们的特征分布分别是$\lambda_1,\lambda_2,\cdots,\lambda_p$, 将特征根"归一化", 既有:
$$w_i = \lambda_i/\sum_{i=1}^m\lambda_i \quad i=1,2,\cdots,p$$
记为$W = (w_1,w_2,\cdots,w_p)&rsquo;$, 由$Y = T&rsquo;X$, 构造综合评价函数为:
$$Z = w_1Y_1 + w_2Y_2 + \cdots + w_pY_p = W&rsquo;Y = W&rsquo;T&rsquo;X = (TW)&lsquo;X \tag{3.2-1}$$
令$TW = w^*_{k \times 1}$, 带入(3.2-1)有<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>$$Z = (w^*)&#39;X \tag{3.2-2}$$
</span></span></code></pre></div>综合评价函数是对原始指标的线性综合, 从计算主成分到对之加权, 经过两次线性运算后得到综合评价函数。</li></ul><h4 id=主成分得分>主成分得分
<a class=header-anchor href=#%e4%b8%bb%e6%88%90%e5%88%86%e5%be%97%e5%88%86></a></h4><ul><li>指将第t个样品(标准化后的数据)的值$X_{(t)} = (X_{t1}, X_{t2}, \cdots, X_{tp})&rsquo;$带入第$i$个主成分$Y_i = T&rsquo;_iX$, 得到的值称为第$t$个样品在第$i$个主成分的得分。</li></ul><h3 id=r应用>R应用
<a class=header-anchor href=#r%e5%ba%94%e7%94%a8></a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-r data-lang=r><span style=display:flex><span>mark <span style=color:#f92672>=</span><span style=color:#a6e22e>read.table</span>(<span style=color:#e6db74>&#34;eg6.1.csv&#34;</span>, sep <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;,&#34;</span>, header <span style=color:#f92672>=</span> T)
</span></span><span style=display:flex><span><span style=color:#75715e># 计算列与列的相关系数</span>
</span></span><span style=display:flex><span>R <span style=color:#f92672>=</span> <span style=color:#a6e22e>round</span>(<span style=color:#a6e22e>cor</span>(mark), <span style=color:#ae81ff>3</span>)
</span></span><span style=display:flex><span><span style=color:#75715e># 使用相关矩阵计算</span>
</span></span><span style=display:flex><span>pca <span style=color:#f92672>=</span> <span style=color:#a6e22e>princomp</span>(mark, cor <span style=color:#f92672>=</span> T)
</span></span><span style=display:flex><span><span style=color:#a6e22e>summary</span>(pca, loadings <span style=color:#f92672>=</span> T)
</span></span><span style=display:flex><span><span style=color:#75715e>#取前2个主成分，分别为课程差异因子和课程均衡因子</span>
</span></span><span style=display:flex><span>pre <span style=color:#f92672>=</span> <span style=color:#a6e22e>round</span>(<span style=color:#a6e22e>predict</span>(pca), <span style=color:#ae81ff>3</span>)
</span></span><span style=display:flex><span>pca<span style=color:#f92672>$</span>scores
</span></span><span style=display:flex><span><span style=color:#a6e22e>screeplot</span>(pca, types <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;lines&#34;</span>)
</span></span><span style=display:flex><span>load <span style=color:#f92672>=</span> <span style=color:#a6e22e>loadings</span>(pca)
</span></span><span style=display:flex><span><span style=color:#a6e22e>plot</span>(load[,<span style=color:#ae81ff>1</span><span style=color:#f92672>:</span><span style=color:#ae81ff>2</span>],xlim<span style=color:#f92672>=</span><span style=color:#a6e22e>c</span>(<span style=color:#ae81ff>-0.6</span>,<span style=color:#ae81ff>0.6</span>),ylim<span style=color:#f92672>=</span><span style=color:#a6e22e>c</span>(<span style=color:#ae81ff>-0.6</span>,<span style=color:#ae81ff>0.6</span>))
</span></span><span style=display:flex><span><span style=color:#a6e22e>text</span>(load[,<span style=color:#ae81ff>1</span>],load[,<span style=color:#ae81ff>2</span>],adj<span style=color:#f92672>=</span><span style=color:#a6e22e>c</span>(<span style=color:#ae81ff>0.5</span>,<span style=color:#ae81ff>-0.5</span>))
</span></span><span style=display:flex><span><span style=color:#a6e22e>abline</span>(h<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span><span style=color:#a6e22e>abline</span>(v<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span><span style=color:#75715e># 主成分得分</span>
</span></span><span style=display:flex><span>score<span style=color:#f92672>=</span><span style=color:#a6e22e>as.matrix</span>(pca<span style=color:#f92672>$</span>scores)
</span></span><span style=display:flex><span>sd<span style=color:#f92672>=</span><span style=color:#a6e22e>as.vector</span>(pca<span style=color:#f92672>$</span>sdev)
</span></span><span style=display:flex><span>weight<span style=color:#f92672>=</span>sd^2<span style=color:#f92672>/</span><span style=color:#a6e22e>sum</span>(sd^2)
</span></span><span style=display:flex><span>tscore<span style=color:#f92672>=</span>score<span style=color:#f92672>%*%</span>weight
</span></span><span style=display:flex><span>outcome<span style=color:#f92672>=</span><span style=color:#a6e22e>data.frame</span>(pca<span style=color:#f92672>$</span>scores,tscore)
</span></span></code></pre></div><h2 id=主成分回归pcr>主成分回归(PCR)
<a class=header-anchor href=#%e4%b8%bb%e6%88%90%e5%88%86%e5%9b%9e%e5%bd%92pcr></a></h2><h3 id=多元线性回归>多元线性回归
<a class=header-anchor href=#%e5%a4%9a%e5%85%83%e7%ba%bf%e6%80%a7%e5%9b%9e%e5%bd%92></a></h3><ul><li>样本回归模型:
$$Y = (I_n \quad X) {\beta_0 \choose \beta} + \mu = \beta_0I_n + X\beta + \mu$$</li><li>模型系数向量估计量为:
$${\beta_0 \choose \beta} = [(I_nX)&rsquo;(I_nX)]^{-1}(I_nX)&lsquo;Y$$</li></ul><h3 id=主成分回归的原理>主成分回归的原理
<a class=header-anchor href=#%e4%b8%bb%e6%88%90%e5%88%86%e5%9b%9e%e5%bd%92%e7%9a%84%e5%8e%9f%e7%90%86></a></h3><ul><li>最小二乘估计的假定前提之一: 自变量不相关, 即自变量之间不存在共线性问题。但在经济管理中, 许多经济变量之间都存在相关关系。</li><li>解决办法<ul><li>先对模型中的自变量进行主成分分析, 并提取一定的主成分;</li><li>然后用因变量对所取的主成分进行回归;</li><li>最后, 再将因变量对所提取的主成分的回归方程转化为对原自变量的回归方程, 即为<strong>主成分回归</strong></li></ul></li><li>对上述回归模型中的自变量$X_1,X_2,\cdots,X_p$的样本观测数据, 若进行主成分分析, 则可得k个主成分分别为:<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>$$
</span></span><span style=display:flex><span>  \begin{cases}
</span></span><span style=display:flex><span>    Z_1 = t_{11}X_1 + t_{12}X_2 + \cdots + t_{1p}X_p \\
</span></span><span style=display:flex><span>    Z_2 = t_{21}X_1 + t_{22}X_2 + \cdots + t_{2p}X_p \\
</span></span><span style=display:flex><span>    \cdots  \\
</span></span><span style=display:flex><span>    Z_k = t_{k1}X_1 + t_{k2}X_2 + \cdots + t_{kk}X_k
</span></span><span style=display:flex><span>  \end{cases}
</span></span><span style=display:flex><span>$$
</span></span></code></pre></div></li><li>记第i个样品在第j个主成分上的得分为$Z_{ij}$, 并记全部样本的主成分得分矩阵为$Z = (z_{ij})_{n \times k}$, 即有:<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>$$Z = 
</span></span><span style=display:flex><span>\begin{bmatrix}
</span></span><span style=display:flex><span>  z_{11} &amp; z_{12} &amp; \cdots &amp; z_{1k} \\
</span></span><span style=display:flex><span>  z_{21} &amp; z_{22} &amp; \cdots &amp; z_{2k} \\
</span></span><span style=display:flex><span>  \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
</span></span><span style=display:flex><span>  z_{n1} &amp; z_{n2} &amp; \cdots &amp; z_{nk} 
</span></span><span style=display:flex><span>\end{bmatrix} \quad
</span></span><span style=display:flex><span>T = \begin{bmatrix}
</span></span><span style=display:flex><span>  t_{11} &amp; t_{12} &amp; \cdots &amp; t_{1k} \\
</span></span><span style=display:flex><span>  t_{21} &amp; t_{22} &amp; \cdots &amp; t_{2k} \\
</span></span><span style=display:flex><span>  \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
</span></span><span style=display:flex><span>  t_{n1} &amp; t_{n2} &amp; \cdots &amp; t_{nk} 
</span></span><span style=display:flex><span>\end{bmatrix}
</span></span><span style=display:flex><span>$$
</span></span></code></pre></div>若主成分分析是根据样本协方差S做出来的, 则主成分的分矩阵为:$Z = X_0T$<br>若主成分分析是根据样本相关矩阵R做出来的, 则主成分的分矩阵为:$<code>$Z^* = X^*T^*$</code>$</li><li>若将主成分得分矩阵(经过中心化或标准化变换)看作是自变量的样本观测矩阵, 建立因变量Y对k个主成分的线性回归方程:<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>$$Y = r_0 + r_1z_1 + \cdot + r_kz_k + \mu \\
</span></span><span style=display:flex><span>或者 \quad Y = r_0^* + r_1^*z_1^* + \cdots + r_k^*z_k^* + \mu$$
</span></span></code></pre></div>此回归方程的因变量与原回归方程的因变量相同, 所以随机误差也相同, 并且$E(\mu) = 0, E(\mu^2) = \sigma^2$, 即可使用最小二乘法进行系数的估计。
模型系数的估计量为:<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>$${\hat{r}_0 \choose \hat{r}} = {n \quad I&#39;_nZ \choose Z&#39;I&#39;_n \quad Z&#39;Z}^{-1}{I_nY \choose Z&#39;Y} \\
</span></span><span style=display:flex><span>或者 {\hat{r}_0^* \choose \hat{r}^*} = {n \quad I&#39;_nZ^* \choose Z^{*&#39;}I&#39;_n \quad Z^{*&#39;}Z}^{-1}{I_nY \choose Z^{*&#39;}Y}
</span></span><span style=display:flex><span>$$
</span></span></code></pre></div>主成分回归的系数向量估计值与相应的原自变量回归系数向量估计值之间的关系:<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>$$\hat{\beta} = T\hat{r} \quad 或者 \quad \hat{\beta}^* = T^*\hat{r}^*$$
</span></span></code></pre></div>根据上述系数值即可得出因变量与原始变量的回归模型。</li></ul></div><footer class=post-footer><div class=post-tags><a href=/tags/%e6%95%b0%e7%90%86%e7%bb%9f%e8%ae%a1>数理统计</a></div><div class=addthis_inline_share_toolbox style=text-align:center></div><hr><div class=post-copyright><img src=/imgs/cc/cc.svg width=75 height=75 align=right alt=共享知识><ul><li class=post-copyright-title><strong>文章标题：</strong>
多元统计之主成分分析</li><li class=post-copyright-author><strong>本文作者： </strong>Patrick</li><li class=post-copyright-link><strong>本文链接：</strong>
<a id=post-cr-link href=/post/principle-component-analysis/ title=多元统计之主成分分析>/post/principle-component-analysis/</a></li><li class=post-copyright-license><strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <i class="fab fa-fw fa-creative-commons"></i><a target=_blank href=https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh>BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div><div class=post-nav><div class="post-nav-next post-nav-item"><a href=/post/factor-analysis/ rel=next title=多元统计之因子分析><i class="fa fa-chevron-left"></i> 多元统计之因子分析</a></div><div class="post-nav-prev post-nav-item"><a href=/post/discrimination-analysis/ rel=prev title=多元统计之判别分析>多元统计之判别分析
<i class="fa fa-chevron-right"></i></a></div></div></footer></article></div></div></main><footer class=footer><div class=footer-inner><div id=gtranslate class=google-translate><i class="fa fa-language"></i><div id=google_translate_element></div></div><div class=copyright>&copy;
<span itemprop=copyrightYear>2015 - 2024
</span><span class=with-love><i class="fa fa-heart"></i>
</span><span class=author itemprop=copyrightHolder>Patrick</span></div><div class=powered-by>由 <a href=https://gohugo.io title=0.121.1 target=_blank>Hugo</a> & <a href=https://github.com/hugo-next/hugo-theme-next title=4.5.3 target=_blank>Hugo NexT.Gemini</a> 强力驱动</div></div></footer><script type=text/javascript src=https://cdn.bootcdn.net/ajax/libs/animejs/3.2.1/anime.min.js defer></script><script type=text/javascript src=https://cdn.bootcdn.net/ajax/libs/viewerjs/1.11.0/viewer.min.js defer></script><script class=next-config data-name=main type=application/json>{"bookmark":{"color":"#222","enable":true,"save":"manual"},"copybtn":true,"darkmode":true,"giscus":{"cfg":{"category":"Comments","categoryid":null,"emit":false,"inputposition":"top","mapping":"title","reactions":false,"repo":"username/repo-name","repoid":null,"theme":"preferred_color_scheme"},"js":"https://giscus.app/client.js"},"hostname":"/","i18n":{"ds_day":" 天前","ds_days":" 天 ","ds_hour":" 小时前","ds_hours":" 小时 ","ds_just":"刚刚","ds_min":" 分钟前","ds_mins":" 分钟","ds_month":" 个月前","ds_years":" 年 ","empty":"没有找到任何搜索结果：${query}","hits":"找到 ${hits} 个搜索结果","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","placeholder":"搜索..."},"lang":"zh-CN","lazyload":false,"localSearch":{"enable":true,"limit":1e3,"path":"/searchindexes.xml","preload":false,"topnperarticle":-1,"trigger":"auto","unescape":false},"motion":{"async":true,"enable":true,"transition":{"collheader":"fadeInLeft","postblock":"fadeIn","postbody":"fadeInDown","postheader":"fadeInDown","sidebar":"fadeInUp"}},"postmeta":{"comments":{"enable":true,"plugin":"waline"},"views":{"enable":true,"plugin":"busuanzi"}},"root":"/","scheme":"Gemini","sidebar":{"display":"post","offset":12,"padding":18,"position":"left","width":256},"vendor":{"plugins":"bootcdn","router":"https://cdn.bootcdn.net/ajax/libs"},"version":"4.5.3","waline":{"cfg":{"emoji":false,"imguploader":false,"placeholder":"请文明发言哟 ヾ(≧▽≦*)o","reaction":true,"reactiontext":["点赞","踩一下","得意","不屑","尴尬","睡觉"],"reactiontitle":"你认为这篇文章怎么样？","requiredmeta":["nick","mail"],"serverurl":null,"sofa":"快来发表你的意见吧 (≧∀≦)ゞ","wordlimit":200},"css":{"alias":"waline","file":"dist/waline.css","name":"@waline/client","version":"2.13.0"},"js":{"alias":"waline","file":"dist/waline.js","name":"@waline/client","version":"2.13.0"}}}</script><script type=text/javascript src=/js/main.min.b0c78e5a4df586ee46d02716ffa91a4a322e56763e04e91eb2ba052c9469ed02.js defer></script><script type=text/javascript src=/js/math.min.a6ada19a368d85dad9ead2040d86ae561a867fafef89391d1aa2aa5909366509.js defer></script></body></html>